{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dax027/OpenAI-ComplianceAPI/blob/main/ChatGPT_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f5bja_7fvo8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4467a4e5-1f07-4efb-a48a-4f1f18c4d5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace: 5cce4c27-054b-43f3-b365-4f25fe4619a6\n",
            "Window UTC: 2025-09-09T00:00:00+00:00 ‚Üí 2025-09-09T23:59:00+00:00\n"
          ]
        }
      ],
      "source": [
        "import requests, datetime as dt, time, random, re\n",
        "from typing import List, Dict, Any, Optional, Iterator\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# ================= REQUIRED CONFIG =========================\n",
        "API_KEY = (userdata.get('compliance') or '').strip()\n",
        "WS_ID   = (userdata.get('WS_ID') or '').strip()\n",
        "assert API_KEY, \"Missing userdata['compliance']\"\n",
        "assert WS_ID,   \"Missing userdata['WS_ID']\"\n",
        "\n",
        "BASE = f\"https://api.chatgpt.com/v1/compliance/workspaces/{WS_ID}\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    \"Accept\": \"application/json\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update(HEADERS)\n",
        "\n",
        "# ================== INPUTS =================================\n",
        "TARGET        = \"francisco.rodriguez4@adventhealth.com\"   # email or a user-‚Ä¶ id\n",
        "# Format: YYYY, MM, DD, hh, mm\n",
        "START_UTC = dt.datetime(2025, 9, 9, 0, 0, tzinfo=dt.timezone.utc)\n",
        "END_UTC   = dt.datetime(2025, 9, 9, 23, 59, tzinfo=dt.timezone.utc)\n",
        "\n",
        "# If we already know the user id, put it here to skip lookup\n",
        "USER_ID_OVERRIDE: Optional[str] = 'user-UmhoJIc8cFKiWqQT6rz8RSwi'  # e.g., \"user-XXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "\n",
        "CONV_LIMIT      = 40        # <=500 per spec; drop if 522s persist\n",
        "USERS_LIMIT     = 200       # default = 200 per spec\n",
        "MAX_RETRIES     = 6\n",
        "BASE_BACKOFF    = 0.6\n",
        "TIMEOUT_CONNECT = 10\n",
        "TIMEOUT_READ    = 120\n",
        "PROBE_MIN_SLICE = dt.timedelta(hours=3)\n",
        "\n",
        "print(\"Workspace:\", WS_ID)\n",
        "print(\"Window UTC:\", START_UTC.isoformat(), \"‚Üí\", END_UTC.isoformat())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WJh0EESstYe6"
      },
      "outputs": [],
      "source": [
        "def _sleep_backoff(attempt: int, base: float = BASE_BACKOFF):\n",
        "    delay = base * (2 ** attempt) + random.uniform(0, base)\n",
        "    time.sleep(min(delay, 10))\n",
        "\n",
        "def _get(url: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "    timeout = (TIMEOUT_CONNECT, TIMEOUT_READ)\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            r = SESSION.get(url, params=params or {}, timeout=timeout)\n",
        "            if r.status_code == 429:\n",
        "                print(\"429 rate-limit ‚Äî backing off\")\n",
        "                _sleep_backoff(attempt); continue\n",
        "            if r.status_code in (522, 524) or 500 <= r.status_code < 600:\n",
        "                print(f\"Server/edge error {r.status_code} ‚Äî retrying\")\n",
        "                _sleep_backoff(attempt); continue\n",
        "            if r.status_code >= 400:\n",
        "                print(\"Compliance API error:\", r.status_code, r.text[:300])\n",
        "                r.raise_for_status()\n",
        "            return r.json()\n",
        "        except requests.RequestException as e:\n",
        "            if attempt == MAX_RETRIES - 1: raise\n",
        "            _sleep_backoff(attempt)\n",
        "    raise RuntimeError(\"Unreachable after retries\")\n",
        "\n",
        "def parse_ts_unix(ts) -> Optional[dt.datetime]:\n",
        "    if ts is None: return None\n",
        "    try:\n",
        "        return dt.datetime.fromtimestamp(float(ts), tz=dt.timezone.utc)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def to_unix_seconds(d: dt.datetime) -> int:\n",
        "    if not d.tzinfo: d = d.replace(tzinfo=dt.timezone.utc)\n",
        "    return int(d.timestamp())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _first_page_conversations(start_utc: dt.datetime, limit: int) -> Dict[str, Any]:\n",
        "    url = f\"{BASE}/conversations\"\n",
        "    params = {\"since_timestamp\": to_unix_seconds(start_utc), \"limit\": min(limit, 500)}\n",
        "    return _get(url, params=params)\n",
        "\n",
        "def _stream_conversations_from_first_page(first_page: Dict[str, Any],\n",
        "                                          start_utc: dt.datetime,\n",
        "                                          end_utc: dt.datetime,\n",
        "                                          limit: int) -> Iterator[Dict[str, Any]]:\n",
        "    url = f\"{BASE}/conversations\"\n",
        "    for conv in first_page.get(\"data\", []): yield conv\n",
        "    after = first_page.get(\"last_id\") if first_page.get(\"has_more\") else None\n",
        "    params = {\"since_timestamp\": to_unix_seconds(start_utc)}\n",
        "    while after:\n",
        "        page = _get(url, params={**params, \"limit\": limit, \"after\": after})\n",
        "        for conv in page.get(\"data\", []): yield conv\n",
        "        after = page.get(\"last_id\") if page.get(\"has_more\") else None\n",
        "\n",
        "def iter_conversations_adaptive(start_utc: dt.datetime,\n",
        "                                end_utc: dt.datetime,\n",
        "                                limit: int,\n",
        "                                min_slice: dt.timedelta = PROBE_MIN_SLICE) -> Iterator[Dict[str, Any]]:\n",
        "    \"\"\"Bisects only on 522/5xx to narrow failing intervals.\"\"\"\n",
        "    stack = [(start_utc, end_utc)]\n",
        "    while stack:\n",
        "        s, e = stack.pop()\n",
        "        if s > e: continue\n",
        "        try:\n",
        "            first = _first_page_conversations(s, limit)\n",
        "            yield from _stream_conversations_from_first_page(first, s, e, limit)\n",
        "        except requests.HTTPError as err:\n",
        "            code = getattr(err.response, \"status_code\", None)\n",
        "            if code and (code in (522, 524) or 500 <= code < 600):\n",
        "                if (e - s) <= min_slice: raise\n",
        "                mid = s + (e - s) / 2\n",
        "                stack.append((s, mid)); stack.append((mid, e))\n",
        "            else: raise\n"
      ],
      "metadata": {
        "id": "N5IArb10uNEG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_ID_RE = re.compile(r\"^user-[A-Za-z0-9]{8,}$\")\n",
        "\n",
        "def resolve_user_id(identifier: str,\n",
        "                    start_utc: dt.datetime,\n",
        "                    end_utc: dt.datetime) -> str:\n",
        "    # If you‚Äôve pinned an override, use it and print it\n",
        "    if USER_ID_OVERRIDE:\n",
        "        print(\"Using USER_ID_OVERRIDE:\", USER_ID_OVERRIDE)\n",
        "        return USER_ID_OVERRIDE\n",
        "\n",
        "    ident = (identifier or \"\").strip()\n",
        "    if USER_ID_RE.match(ident):\n",
        "        print(\"Identifier is already a user_id:\", ident)\n",
        "        print(\"Resolved user id:\", ident)\n",
        "        return ident\n",
        "\n",
        "    assert \"@\" in ident, \"Identifier must be an email or a user-‚Ä¶ id\"\n",
        "    email = ident.lower()\n",
        "\n",
        "    print(f\"Resolving user ID via /users for {email}\")\n",
        "    url = f\"{BASE}/users\"\n",
        "    after = None\n",
        "    limit = min(max(USERS_LIMIT, 1), 200)\n",
        "    last_call = 0.0\n",
        "    pages = 0\n",
        "\n",
        "    while True:\n",
        "        # pace to ‚â§50 req/min\n",
        "        elapsed = time.time() - last_call\n",
        "        if elapsed < 1.25:\n",
        "            time.sleep(1.25 - elapsed)\n",
        "        params = {\"limit\": limit}\n",
        "        if after:\n",
        "            params[\"after\"] = after\n",
        "        data = _get(url, params=params)\n",
        "        last_call = time.time()\n",
        "        pages += 1\n",
        "\n",
        "        for u in data.get(\"data\", []):\n",
        "            if (u.get(\"email\") or \"\").lower() == email:\n",
        "                uid = u.get(\"id\")\n",
        "                print(f\"Found via /users on page {pages}.\")\n",
        "                print(\"Resolved user id:\", uid)\n",
        "                return uid\n",
        "\n",
        "        if not data.get(\"has_more\"):\n",
        "            print(\"End of /users ‚Äî no match, falling back to probe.\")\n",
        "            break\n",
        "        after = data.get(\"last_id\")\n",
        "        if pages % 10 == 0:\n",
        "            print(f\"‚Ä¶/users pages scanned: {pages}\")\n",
        "\n",
        "    print(\"Probing conversations to infer user id‚Ä¶\")\n",
        "    scanned = 0\n",
        "    for conv in iter_conversations_adaptive(start_utc, end_utc, limit=min(40, CONV_LIMIT)):\n",
        "        scanned += 1\n",
        "        if (conv.get(\"user_email\") or \"\").lower() == email and conv.get(\"user_id\"):\n",
        "            uid = conv[\"user_id\"]\n",
        "            print(\"Found via conversation.user_id.\")\n",
        "            print(\"Resolved user id:\", uid)\n",
        "            return uid\n",
        "        for m in ((conv.get(\"messages\") or {}).get(\"data\") or []):\n",
        "            a = m.get(\"author\") or {}\n",
        "            if (a.get(\"email\") or \"\").lower() == email and a.get(\"id\"):\n",
        "                uid = a[\"id\"]\n",
        "                print(\"Found via message.author.id.\")\n",
        "                print(\"Resolved user id:\", uid)\n",
        "                return uid\n",
        "        if scanned % 20 == 0:\n",
        "            print(f\"‚Ä¶probed {scanned} conversations\")\n",
        "\n",
        "    raise RuntimeError(f\"Could not resolve user_id for {email}\")\n"
      ],
      "metadata": {
        "id": "DjVV4hotr6sN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pin_user_id_override(uid: str):\n",
        "    global USER_ID_OVERRIDE\n",
        "    USER_ID_OVERRIDE = uid\n",
        "    print(\"USER_ID_OVERRIDE pinned:\", USER_ID_OVERRIDE)\n",
        "\n",
        "# Example after resolving once:\n",
        "# uid = resolve_user_id(TARGET, START_UTC, END_UTC)\n",
        "# pin_user_id_override(uid)\n"
      ],
      "metadata": {
        "id": "uVq6xGUyCfGI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iter_conversations_for_user_window(user_id: str,\n",
        "                                       start_utc: dt.datetime,\n",
        "                                       end_utc: dt.datetime,\n",
        "                                       limit: int = CONV_LIMIT) -> Iterator[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    - First page: since_timestamp + users + file_format=id (lighter payload)\n",
        "    - Next pages: after + users + file_format=id\n",
        "    - On 5xx/522: backoff and shrink current limit to reduce payload\n",
        "    - Gentle pacing between pages\n",
        "    \"\"\"\n",
        "    url = f\"{BASE}/conversations\"\n",
        "    limit_cur = max(10, min(int(limit), 500))\n",
        "    base_params = {\"users\": user_id, \"file_format\": \"id\"}\n",
        "\n",
        "    def _page(params, max_attempts=6):\n",
        "        nonlocal limit_cur\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                return _get(url, params=params)\n",
        "            except requests.HTTPError as err:\n",
        "                code = getattr(err.response, \"status_code\", None)\n",
        "                if code and (code in (522, 524) or 500 <= code < 600):\n",
        "                    if limit_cur > 20:\n",
        "                        limit_cur = max(20, limit_cur // 2)\n",
        "                        print(f\"5xx on conversations ‚Äî shrinking limit to {limit_cur}\")\n",
        "                    _sleep_backoff(attempt)\n",
        "                    continue\n",
        "                raise\n",
        "\n",
        "    # First page (since_timestamp)\n",
        "    first_params = {**base_params, \"since_timestamp\": to_unix_seconds(start_utc), \"limit\": limit_cur}\n",
        "    first = _page(first_params)\n",
        "\n",
        "    for conv in (first.get(\"data\") or []):\n",
        "        la = parse_ts_unix(conv.get(\"last_active_at\"))\n",
        "        if la and la > end_utc:\n",
        "            continue\n",
        "        yield conv\n",
        "\n",
        "    after = first.get(\"last_id\") if first.get(\"has_more\") else None\n",
        "\n",
        "    # Follow-on pages (after)\n",
        "    while after:\n",
        "        time.sleep(0.3)  # gentle pacing\n",
        "        page = _page({**base_params, \"after\": after, \"limit\": limit_cur})\n",
        "        for conv in (page.get(\"data\") or []):\n",
        "            la = parse_ts_unix(conv.get(\"last_active_at\"))\n",
        "            if la and la > end_utc:\n",
        "                continue\n",
        "            yield conv\n",
        "        after = page.get(\"last_id\") if page.get(\"has_more\") else None\n",
        "\n",
        "\n",
        "def flatten_messages_from_conversation(conv: Dict[str, Any],\n",
        "                                       start_utc: dt.datetime,\n",
        "                                       end_utc: dt.datetime) -> List[Dict[str, Any]]:\n",
        "    out = []\n",
        "    for m in ((conv.get(\"messages\") or {}).get(\"data\") or []):\n",
        "        ts = parse_ts_unix(m.get(\"created_at\"))\n",
        "        if not ts or ts < start_utc or ts > end_utc:\n",
        "            continue\n",
        "        a = m.get(\"author\") or {}; c = m.get(\"content\") or {}\n",
        "        files = ((m.get(\"files\") or {}).get(\"data\") or [])\n",
        "        f_summary = \"; \".join(f\"{f.get('name','(no name)')}|{f.get('id','')}\" for f in files)\n",
        "        out.append({\n",
        "            \"conversation_id\": conv.get(\"id\"),\n",
        "            \"conversation_title\": conv.get(\"title\"),\n",
        "            \"message_id\": m.get(\"id\"),\n",
        "            \"message_created_at\": ts.isoformat(),\n",
        "            \"author_role\": a.get(\"role\"),\n",
        "            \"author_id\": a.get(\"id\"),\n",
        "            \"author_email\": a.get(\"email\"),\n",
        "            \"content_type\": c.get(\"type\"),\n",
        "            \"content_value\": c.get(\"value\"),\n",
        "            \"file_summary\": f_summary,\n",
        "        })\n",
        "    return out\n",
        "\n",
        "\n",
        "def collect_user_messages_window(identifier: str,\n",
        "                                 start_utc: dt.datetime,\n",
        "                                 end_utc: dt.datetime) -> List[Dict[str, Any]]:\n",
        "    user_id = resolve_user_id(identifier, start_utc, end_utc)\n",
        "    all_rows = []\n",
        "    scanned = 0\n",
        "    for conv in iter_conversations_for_user_window(user_id, start_utc, end_utc, limit=CONV_LIMIT):\n",
        "        scanned += 1\n",
        "        rows = flatten_messages_from_conversation(conv, start_utc, end_utc)\n",
        "        all_rows.extend(rows)\n",
        "        if scanned % 25 == 0:\n",
        "            print(f\"Processed {scanned} conversations; {len(all_rows)} messages so far.\")\n",
        "    print(f\"Conversations considered: {scanned}\")\n",
        "    print(f\"Messages in window: {len(all_rows)}\")\n",
        "    return all_rows\n"
      ],
      "metadata": {
        "id": "O4VZ_FC-sFKE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: list conversations in Eastern Time, with file counts (no auto-export)\n",
        "import pytz\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.width\", 0)\n",
        "\n",
        "eastern = pytz.timezone(\"US/Eastern\")\n",
        "\n",
        "uid = resolve_user_id(TARGET, START_UTC, END_UTC)\n",
        "print(\"Target user id:\", uid)\n",
        "\n",
        "CONV_CACHE: Dict[str, Dict[str, Any]] = {}\n",
        "rows = []\n",
        "\n",
        "for i, conv in enumerate(iter_conversations_for_user_window(uid, START_UTC, END_UTC, limit=CONV_LIMIT), 1):\n",
        "    conv_id = conv.get(\"id\")\n",
        "    title = conv.get(\"title\")\n",
        "\n",
        "    # timestamps\n",
        "    last_active_utc = parse_ts_unix(conv.get(\"last_active_at\"))\n",
        "    last_active_et = (\n",
        "        pd.to_datetime(last_active_utc, utc=True).tz_convert(eastern)\n",
        "        if last_active_utc else None\n",
        "    )\n",
        "\n",
        "    # message + file counts\n",
        "    msgs = ((conv.get(\"messages\") or {}).get(\"data\")) or []\n",
        "    message_count = len(msgs)\n",
        "\n",
        "    # Sum file references across all messages\n",
        "    total_files = 0\n",
        "    sample_file_ids = []\n",
        "    for m in msgs:\n",
        "        files = ((m.get(\"files\") or {}).get(\"data\")) or []\n",
        "        total_files += len(files)\n",
        "        # preview a few file ids for situational awareness\n",
        "        for f in files:\n",
        "            fid = f.get(\"id\")\n",
        "            if fid and len(sample_file_ids) < 5:\n",
        "                sample_file_ids.append(fid)\n",
        "\n",
        "    if conv_id:\n",
        "        CONV_CACHE[conv_id] = conv\n",
        "        rows.append({\n",
        "            \"conversation_id\": conv_id,\n",
        "            \"conversation_title\": title,\n",
        "            \"last_active_et\": last_active_et.isoformat() if last_active_et else None,\n",
        "            \"message_count\": message_count,\n",
        "            \"file_count\": total_files,\n",
        "            \"sample_file_ids\": \", \".join(sample_file_ids) if sample_file_ids else None,\n",
        "        })\n",
        "\n",
        "    if i % 25 == 0:\n",
        "        print(f\"‚Ä¶indexed {i} conversations so far\")\n",
        "\n",
        "conv_df = pd.DataFrame(rows)\n",
        "if not conv_df.empty:\n",
        "    conv_df[\"last_active_et_parsed\"] = pd.to_datetime(conv_df[\"last_active_et\"])\n",
        "    conv_df = conv_df.sort_values(\"last_active_et_parsed\", ascending=False).drop(columns=[\"last_active_et_parsed\"])\n",
        "    display(conv_df.head(100))\n",
        "else:\n",
        "    print(\"No conversations found in the selected window.\")\n",
        "\n",
        "def export_conversations_index(path=\"/content/conversations_index.csv\"):\n",
        "    \"\"\"Export conversation index manually.\"\"\"\n",
        "    if 'conv_df' not in globals() or conv_df.empty:\n",
        "        print(\"Nothing to export.\")\n",
        "        return\n",
        "    conv_df.to_csv(path, index=False)\n",
        "    print(\"Exported to:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "TrJ6mX9mGJJC",
        "outputId": "3ce6520f-1c86-4342-a762-9b37dd87dc96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using USER_ID_OVERRIDE: user-UmhoJIc8cFKiWqQT6rz8RSwi\n",
            "Target user id: user-UmhoJIc8cFKiWqQT6rz8RSwi\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        conversation_id        conversation_title  \\\n",
              "1  68b2010f-4470-8330-8451-a6d66df0ff66     Greeting conversation   \n",
              "0  68ac7ae9-f67c-8332-90fa-2d5d711de754  Export PrintService logs   \n",
              "\n",
              "                     last_active_et  message_count  file_count  \\\n",
              "1  2025-09-09T16:12:52.611337-04:00             39           6   \n",
              "0  2025-09-09T09:11:27.443272-04:00             79           0   \n",
              "\n",
              "                                                                                                                                   sample_file_ids  \n",
              "1  file-1YQZUW1KHTwWzN7E8rbVer, file-YX11Ht6JTKnFdFeRfxj8Qg, file-XCMYLaqbJZaMgy2JVFC4WE, file-VUciHnTy49zQ1KjgVWV4oF, file-VuYRoRVxuEBFZKZjX95P4x  \n",
              "0                                                                                                                                             None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-652ee975-2888-413f-afee-6dc46445579d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>conversation_title</th>\n",
              "      <th>last_active_et</th>\n",
              "      <th>message_count</th>\n",
              "      <th>file_count</th>\n",
              "      <th>sample_file_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68b2010f-4470-8330-8451-a6d66df0ff66</td>\n",
              "      <td>Greeting conversation</td>\n",
              "      <td>2025-09-09T16:12:52.611337-04:00</td>\n",
              "      <td>39</td>\n",
              "      <td>6</td>\n",
              "      <td>file-1YQZUW1KHTwWzN7E8rbVer, file-YX11Ht6JTKnFdFeRfxj8Qg, file-XCMYLaqbJZaMgy2JVFC4WE, file-VUciHnTy49zQ1KjgVWV4oF, file-VuYRoRVxuEBFZKZjX95P4x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68ac7ae9-f67c-8332-90fa-2d5d711de754</td>\n",
              "      <td>Export PrintService logs</td>\n",
              "      <td>2025-09-09T09:11:27.443272-04:00</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-652ee975-2888-413f-afee-6dc46445579d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-652ee975-2888-413f-afee-6dc46445579d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-652ee975-2888-413f-afee-6dc46445579d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2e494326-0821-4743-aaeb-238990d76c3f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e494326-0821-4743-aaeb-238990d76c3f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2e494326-0821-4743-aaeb-238990d76c3f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"Exported to:\\\", path)\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"conversation_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"68ac7ae9-f67c-8332-90fa-2d5d711de754\",\n          \"68b2010f-4470-8330-8451-a6d66df0ff66\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Export PrintService logs\",\n          \"Greeting conversation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_active_et\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2025-09-09T09:11:27.443272-04:00\",\n          \"2025-09-09T16:12:52.611337-04:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 39,\n        \"max\": 79,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          79,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample_file_ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"file-1YQZUW1KHTwWzN7E8rbVer, file-YX11Ht6JTKnFdFeRfxj8Qg, file-XCMYLaqbJZaMgy2JVFC4WE, file-VUciHnTy49zQ1KjgVWV4oF, file-VuYRoRVxuEBFZKZjX95P4x\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: drill into one conversation, full message text in ET + file details (no auto-export)\n",
        "import pytz\n",
        "\n",
        "def messages_df_for(conversation_id: str,\n",
        "                    start_utc: dt.datetime,\n",
        "                    end_utc: dt.datetime,\n",
        "                    tz: str = \"US/Eastern\") -> pd.DataFrame:\n",
        "    \"\"\"Build DataFrame of messages for one conversation from CONV_CACHE, including file columns.\"\"\"\n",
        "    if conversation_id not in CONV_CACHE:\n",
        "        print(\"Conversation not in cache:\", conversation_id)\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    conv = CONV_CACHE[conversation_id]\n",
        "    msgs = ((conv.get(\"messages\") or {}).get(\"data\")) or []\n",
        "\n",
        "    rows = []\n",
        "    for m in msgs:\n",
        "        ts_utc = parse_ts_unix(m.get(\"created_at\"))\n",
        "        if not ts_utc or ts_utc < start_utc or ts_utc > end_utc:\n",
        "            continue\n",
        "\n",
        "        author = m.get(\"author\") or {}\n",
        "        content = m.get(\"content\") or {}\n",
        "\n",
        "        files = ((m.get(\"files\") or {}).get(\"data\") or [])\n",
        "        file_ids = [f.get(\"id\") for f in files if f.get(\"id\")]\n",
        "        # Some schemas include name; if missing, we‚Äôll show None gracefully\n",
        "        file_names = [f.get(\"name\") for f in files if f.get(\"name\")]\n",
        "\n",
        "        rows.append({\n",
        "            \"message_created_at\": ts_utc.isoformat(),  # UTC ISO\n",
        "            \"author_role\": author.get(\"role\"),\n",
        "            \"author_email\": author.get(\"email\"),\n",
        "            \"content_value\": content.get(\"value\"),     # full text; no truncation due to pandas option\n",
        "            \"message_id\": m.get(\"id\"),\n",
        "            \"file_count\": len(files),\n",
        "            \"file_ids\": \", \".join(file_ids) if file_ids else None,\n",
        "            \"file_names\": \", \".join(file_names) if file_names else None,\n",
        "        })\n",
        "\n",
        "    if not rows:\n",
        "        print(\"No messages for that conversation in window.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    dfm = pd.DataFrame(rows).sort_values(\"message_created_at\")\n",
        "    tzinfo = pytz.timezone(tz)\n",
        "    dfm[\"message_created_at_et\"] = (\n",
        "        pd.to_datetime(dfm[\"message_created_at\"], utc=True).dt.tz_convert(tzinfo)\n",
        "    )\n",
        "    return dfm\n",
        "\n",
        "# Example: pick first conversation\n",
        "if 'conv_df' in globals() and not conv_df.empty:\n",
        "    conv_id = conv_df.iloc[0][\"conversation_id\"]\n",
        "    print(\"Selected conversation:\", conv_id)\n",
        "    df_msgs = messages_df_for(conv_id, START_UTC, END_UTC)\n",
        "    if not df_msgs.empty:\n",
        "        display(df_msgs[[\n",
        "            \"message_created_at_et\",\"author_role\",\"author_email\",\"content_value\",\n",
        "            \"file_count\",\"file_names\",\"file_ids\",\"message_id\"\n",
        "        ]])\n",
        "else:\n",
        "    print(\"Run Cell 7 first to build conv_df.\")\n",
        "\n",
        "def export_messages_for(conversation_id: str, path=\"/content/messages.csv\"):\n",
        "    \"\"\"Export messages manually if desired.\"\"\"\n",
        "    dfm = messages_df_for(conversation_id, START_UTC, END_UTC)\n",
        "    if dfm.empty:\n",
        "        print(\"No messages to export.\")\n",
        "        return\n",
        "    dfm.to_csv(path, index=False)\n",
        "    print(\"Exported messages to:\", path)\n"
      ],
      "metadata": {
        "id": "13mxG4NBV0Z7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1589
        },
        "outputId": "b3a9ff95-c9a3-4f27-fd5a-e0a54eb09d98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected conversation: 68b2010f-4470-8330-8451-a6d66df0ff66\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              message_created_at_et author_role author_email  \\\n",
              "0  2025-09-09 14:33:46.577000-04:00        user         None   \n",
              "1  2025-09-09 14:33:49.116652-04:00      system         None   \n",
              "2  2025-09-09 14:33:49.179349-04:00   assistant         None   \n",
              "3  2025-09-09 14:37:26.248000-04:00        user         None   \n",
              "4  2025-09-09 14:37:28.230157-04:00      system         None   \n",
              "5  2025-09-09 14:37:28.244915-04:00   assistant         None   \n",
              "6  2025-09-09 14:37:42.307995-04:00        tool         None   \n",
              "7  2025-09-09 14:37:42.506574-04:00   assistant         None   \n",
              "8  2025-09-09 14:37:48.416167-04:00        tool         None   \n",
              "9  2025-09-09 14:37:49.781429-04:00   assistant         None   \n",
              "10 2025-09-09 14:37:56.237101-04:00        tool         None   \n",
              "11 2025-09-09 14:37:57.812203-04:00   assistant         None   \n",
              "12 2025-09-09 14:40:48.676000-04:00        user         None   \n",
              "13 2025-09-09 14:40:49.797065-04:00   assistant         None   \n",
              "14 2025-09-09 14:40:56.966395-04:00   assistant         None   \n",
              "15 2025-09-09 14:40:57.405377-04:00        tool         None   \n",
              "17 2025-09-09 14:40:58.391165-04:00   assistant         None   \n",
              "16 2025-09-09 14:41:04.573895-04:00        tool         None   \n",
              "18 2025-09-09 14:41:05.219232-04:00   assistant         None   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 content_value  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      New Ask   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         None   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Got it üëç ‚Äî what‚Äôs your new ask?   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Parse the data and create a excel file that is going to show The PrintServers with the number of Printers, SizeMB and Pages printer per date   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         None   \n",
              "5                                                                                                                                                                                                                                                                                                                                    import pandas as pd\\r\\nimport glob\\r\\nimport os\\r\\n\\r\\n# File paths from uploaded files\\r\\nfiles = [\\r\\n    \"/mnt/data/FHOVPRNF001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNE001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRND001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNC001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNB001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNA001 Parsed_Data_20250909.csv\",\\r\\n]\\r\\n\\r\\n# Load all CSVs into a single DataFrame with PrintServer identification\\r\\ndf_list = []\\r\\nfor f in files:\\r\\n    try:\\r\\n        temp = pd.read_csv(f)\\r\\n        temp[\"PrintServer\"] = os.path.basename(f).split()[0]  # Extract server name\\r\\n        df_list.append(temp)\\r\\n    except Exception as e:\\r\\n        print(f\"Error reading {f}: {e}\")\\r\\n\\r\\ndf = pd.concat(df_list, ignore_index=True)\\r\\n\\r\\n# Inspect structure\\r\\ndf.head()   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Code execution state reset.   \n",
              "7                                                                                                                                                                                                                                                                                                       import pandas as pd\\r\\nimport os\\r\\n\\r\\n# File paths again after reset\\r\\nfiles = [\\r\\n    \"/mnt/data/FHOVPRNF001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNE001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRND001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNC001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNB001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNA001 Parsed_Data_20250909.csv\",\\r\\n]\\r\\n\\r\\n# Load all CSVs into a single DataFrame with PrintServer identification\\r\\ndf_list = []\\r\\nfor f in files:\\r\\n    try:\\r\\n        temp = pd.read_csv(f)\\r\\n        temp[\"PrintServer\"] = os.path.basename(f).split()[0]  # Extract server name\\r\\n        df_list.append(temp)\\r\\n    except Exception as e:\\r\\n        print(f\"Error reading {f}: {e}\")\\r\\n\\r\\ndf = pd.concat(df_list, ignore_index=True)\\r\\n\\r\\n# Show first rows and columns to understand structure\\r\\ndf.head(), df.columns   \n",
              "8   (            TimeCreated    User        Machine  \\\\n 0  9/9/2025 11:41:43 AM  DPOC63    FMGLD1THD74   \\n 1  9/9/2025 11:41:32 AM  KGE87C    FMGD51KCPR3   \\n 2  9/9/2025 11:41:22 AM  NLWF4E    ALTDGRG1PK3   \\n 3  9/9/2025 11:41:11 AM  AKC365    FMGD9D9LG04   \\n 4  9/9/2025 11:41:04 AM  BMAAB0  FMGDAHBXZMMH3   \\n \\n                                         DocumentName Printer  PrintServer  \\\\n 0                                            Hybrent    OPA4  FHOVPRNF001   \\n 1                                        about_blank    NGF4  FHOVPRNF001   \\n 2                                        request.pdf    IWF2  FHOVPRNF001   \\n 3  Insurance Card - MRN_ 506269459 - Pt. Name_ BR...    NF82  FHOVPRNF001   \\n 4    EpicPDFSpooler_24BBCE7CA96E4BFB8E6A3303E2E42F17    OMJZ  FHOVPRNF001   \\n \\n      PrinterPort  SizeMB  PagesPrinted  \\n 0   10.100.39.52    0.86             1  \\n 1  10.28.244.217    0.38             2  \\n 2  10.16.246.255   31.09             2  \\n 3   10.48.247.51    0.21             1  \\n 4     10.89.8.29    0.28             1  ,\\n Index(['TimeCreated', 'User', 'Machine', 'DocumentName', 'Printer',\\n        'PrintServer', 'PrinterPort', 'SizeMB', 'PagesPrinted'],\\n       dtype='object'))   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       # Convert TimeCreated to datetime for grouping by date\\r\\ndf[\"TimeCreated\"] = pd.to_datetime(df[\"TimeCreated\"], errors=\"coerce\")\\r\\n\\r\\n# Extract date only\\r\\ndf[\"Date\"] = df[\"TimeCreated\"].dt.date\\r\\n\\r\\n# Group by PrintServer and Date\\r\\nsummary = df.groupby([\"PrintServer\", \"Date\"]).agg(\\r\\n    NumberOfPrinters=(\"Printer\", \"nunique\"),\\r\\n    TotalSizeMB=(\"SizeMB\", \"sum\"),\\r\\n    TotalPages=(\"PagesPrinted\", \"sum\")\\r\\n).reset_index()\\r\\n\\r\\n# Save to Excel\\r\\noutput_path = \"/mnt/data/PrintServer_Summary.xlsx\"\\r\\nsummary.to_excel(output_path, index=False)\\r\\n\\r\\nimport ace_tools as tools; tools.display_dataframe_to_user(\"Print Server Summary\", summary)\\r\\n\\r\\noutput_path   \n",
              "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        '/mnt/data/PrintServer_Summary.xlsx'   \n",
              "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I‚Äôve parsed the data and created a summary Excel file that shows:  \\n\\n- **PrintServer**  \\n- **Date**  \\n- **Number of Printers**  \\n- **Total Size (MB)**  \\n- **Total Pages Printed**  \\n\\nüìÇ [Download PrintServer Summary Excel](sandbox:/mnt/data/PrintServer_Summary.xlsx)  \\n\\nWould you like me to also create a **per-printer breakdown** (not just server-level) so you can see printer-level usage trends?   \n",
              "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Yes   \n",
              "13                                                                                                                                                                                                                                                                                                                                                                                                                                                         # Create per-printer breakdown grouped by PrintServer, Date, and Printer\\r\\nprinter_summary = df.groupby([\"PrintServer\", \"Date\", \"Printer\"]).agg(\\r\\n    TotalSizeMB=(\"SizeMB\", \"sum\"),\\r\\n    TotalPages=(\"PagesPrinted\", \"sum\")\\r\\n).reset_index()\\r\\n\\r\\n# Save to Excel with two sheets: Server summary + Printer summary\\r\\noutput_path_detailed = \"/mnt/data/PrintServer_Detailed_Summary.xlsx\"\\r\\n\\r\\nwith pd.ExcelWriter(output_path_detailed, engine=\"xlsxwriter\") as writer:\\r\\n    summary.to_excel(writer, sheet_name=\"Server_Summary\", index=False)\\r\\n    printer_summary.to_excel(writer, sheet_name=\"Printer_Summary\", index=False)\\r\\n\\r\\nimport ace_tools as tools; tools.display_dataframe_to_user(\"Print Server Detailed Summary\", printer_summary)\\r\\n\\r\\noutput_path_detailed   \n",
              "14                                                                                                                                                                                                                                                                                                                                                                                                                                                             # Group by PrintServer, Date, and individual Printer\\r\\nper_printer_summary = df.groupby([\"PrintServer\", \"Date\", \"Printer\"]).agg(\\r\\n    TotalSizeMB=(\"SizeMB\", \"sum\"),\\r\\n    TotalPages=(\"PagesPrinted\", \"sum\")\\r\\n).reset_index()\\r\\n\\r\\n# Save to Excel with two sheets: Server Summary + Printer Breakdown\\r\\noutput_path_detailed = \"/mnt/data/PrintServer_Detailed_Summary.xlsx\"\\r\\nwith pd.ExcelWriter(output_path_detailed, engine=\"xlsxwriter\") as writer:\\r\\n    summary.to_excel(writer, sheet_name=\"Server_Summary\", index=False)\\r\\n    per_printer_summary.to_excel(writer, sheet_name=\"Per_Printer_Breakdown\", index=False)\\r\\n\\r\\nimport ace_tools as tools; tools.display_dataframe_to_user(\"Print Server Detailed Summary\", per_printer_summary)\\r\\n\\r\\noutput_path_detailed   \n",
              "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               '/mnt/data/PrintServer_Detailed_Summary.xlsx'   \n",
              "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Here‚Äôs the updated Excel file with **two sheets**:  \\n\\n- **Server_Summary** ‚Üí Total printers, pages, and size per server per day  \\n- **Printer_Summary** ‚Üí Detailed breakdown per printer, per server, per day  \\n\\nüìÇ [Download PrintServer Detailed Summary Excel](sandbox:/mnt/data/PrintServer_Detailed_Summary.xlsx)  \\n\\nDo you want me to also add **charts** (e.g., pages per server over time) inside the Excel for easier visualization?   \n",
              "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               '/mnt/data/PrintServer_Detailed_Summary.xlsx'   \n",
              "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Here‚Äôs the enhanced Excel report with **two sheets**:  \\n\\n1. **Server_Summary** ‚Üí Totals per PrintServer per date  \\n2. **Per_Printer_Breakdown** ‚Üí Usage per Printer (SizeMB & Pages)  \\n\\nüìÇ [Download Detailed PrintServer Summary Excel](sandbox:/mnt/data/PrintServer_Detailed_Summary.xlsx)  \\n\\nDo you want me to also add **charts/visuals** (e.g., pages printed per server over time)?   \n",
              "\n",
              "    file_count  \\\n",
              "0            0   \n",
              "1            0   \n",
              "2            0   \n",
              "3            6   \n",
              "4            0   \n",
              "5            0   \n",
              "6            0   \n",
              "7            0   \n",
              "8            0   \n",
              "9            0   \n",
              "10           0   \n",
              "11           0   \n",
              "12           0   \n",
              "13           0   \n",
              "14           0   \n",
              "15           0   \n",
              "17           0   \n",
              "16           0   \n",
              "18           0   \n",
              "\n",
              "                                                                                                                                                                                                                            file_names  \\\n",
              "0                                                                                                                                                                                                                                 None   \n",
              "1                                                                                                                                                                                                                                 None   \n",
              "2                                                                                                                                                                                                                                 None   \n",
              "3   FHOVPRNF001 Parsed_Data_20250909.csv, FHOVPRNE001 Parsed_Data_20250909.csv, FHOVPRND001 Parsed_Data_20250909.csv, FHOVPRNC001 Parsed_Data_20250909.csv, FHOVPRNB001 Parsed_Data_20250909.csv, FHOVPRNA001 Parsed_Data_20250909.csv   \n",
              "4                                                                                                                                                                                                                                 None   \n",
              "5                                                                                                                                                                                                                                 None   \n",
              "6                                                                                                                                                                                                                                 None   \n",
              "7                                                                                                                                                                                                                                 None   \n",
              "8                                                                                                                                                                                                                                 None   \n",
              "9                                                                                                                                                                                                                                 None   \n",
              "10                                                                                                                                                                                                                                None   \n",
              "11                                                                                                                                                                                                                                None   \n",
              "12                                                                                                                                                                                                                                None   \n",
              "13                                                                                                                                                                                                                                None   \n",
              "14                                                                                                                                                                                                                                None   \n",
              "15                                                                                                                                                                                                                                None   \n",
              "17                                                                                                                                                                                                                                None   \n",
              "16                                                                                                                                                                                                                                None   \n",
              "18                                                                                                                                                                                                                                None   \n",
              "\n",
              "                                                                                                                                                                        file_ids  \\\n",
              "0                                                                                                                                                                           None   \n",
              "1                                                                                                                                                                           None   \n",
              "2                                                                                                                                                                           None   \n",
              "3   file-1YQZUW1KHTwWzN7E8rbVer, file-YX11Ht6JTKnFdFeRfxj8Qg, file-XCMYLaqbJZaMgy2JVFC4WE, file-VUciHnTy49zQ1KjgVWV4oF, file-VuYRoRVxuEBFZKZjX95P4x, file-Wzh28UZqpzwDHegtgLbxjw   \n",
              "4                                                                                                                                                                           None   \n",
              "5                                                                                                                                                                           None   \n",
              "6                                                                                                                                                                           None   \n",
              "7                                                                                                                                                                           None   \n",
              "8                                                                                                                                                                           None   \n",
              "9                                                                                                                                                                           None   \n",
              "10                                                                                                                                                                          None   \n",
              "11                                                                                                                                                                          None   \n",
              "12                                                                                                                                                                          None   \n",
              "13                                                                                                                                                                          None   \n",
              "14                                                                                                                                                                          None   \n",
              "15                                                                                                                                                                          None   \n",
              "17                                                                                                                                                                          None   \n",
              "16                                                                                                                                                                          None   \n",
              "18                                                                                                                                                                          None   \n",
              "\n",
              "                              message_id  \n",
              "0   68f972ac-908d-4e6f-8d76-8e85596b930a  \n",
              "1   1a3044ef-b4a3-4f27-8b00-ebbbac7f5101  \n",
              "2   4d7f7c36-85bc-4df1-9929-bf2d0ff438ab  \n",
              "3   e10e7397-4a61-4c68-8d19-9a4e8e37b0b8  \n",
              "4   18731f11-b470-493c-9d97-2a74f1a64e21  \n",
              "5   53c42575-de9f-45f1-b08e-62e02bf56b55  \n",
              "6   6bab5cdd-e406-49f1-8d74-62ef06fdf78c  \n",
              "7   34fb6727-f2e0-499d-84d1-bce66561bb67  \n",
              "8   45642b36-1e73-474e-acdb-65a88bbe9350  \n",
              "9   889f475c-7a21-42c6-b099-6715b89c64b9  \n",
              "10  9aec3d6d-49ac-45d0-a547-275538826cae  \n",
              "11  6a3ba228-f2d1-4052-be61-adad34002242  \n",
              "12  7e5cc5ed-1f29-45a6-bc85-1f9d25b46c5b  \n",
              "13  ac318088-76c3-405f-b69a-5bc49be19e3a  \n",
              "14  6623df83-e59c-49a1-ad1d-17a8b59a7b71  \n",
              "15  05526889-918e-4c68-a3f0-616fd1189830  \n",
              "17  02c5c52f-951c-402e-bf0a-b118582628a4  \n",
              "16  b23648b7-7e1e-42a6-96f2-51043a939faf  \n",
              "18  f62f79e1-b819-424f-b047-8121a54f2fac  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df36af9f-4b7a-4824-b355-9ef28e0904d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message_created_at_et</th>\n",
              "      <th>author_role</th>\n",
              "      <th>author_email</th>\n",
              "      <th>content_value</th>\n",
              "      <th>file_count</th>\n",
              "      <th>file_names</th>\n",
              "      <th>file_ids</th>\n",
              "      <th>message_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-09 14:33:46.577000-04:00</td>\n",
              "      <td>user</td>\n",
              "      <td>None</td>\n",
              "      <td>New Ask</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>68f972ac-908d-4e6f-8d76-8e85596b930a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-09 14:33:49.116652-04:00</td>\n",
              "      <td>system</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1a3044ef-b4a3-4f27-8b00-ebbbac7f5101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-09 14:33:49.179349-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td>Got it üëç ‚Äî what‚Äôs your new ask?</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>4d7f7c36-85bc-4df1-9929-bf2d0ff438ab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-09 14:37:26.248000-04:00</td>\n",
              "      <td>user</td>\n",
              "      <td>None</td>\n",
              "      <td>Parse the data and create a excel file that is going to show The PrintServers with the number of Printers, SizeMB and Pages printer per date</td>\n",
              "      <td>6</td>\n",
              "      <td>FHOVPRNF001 Parsed_Data_20250909.csv, FHOVPRNE001 Parsed_Data_20250909.csv, FHOVPRND001 Parsed_Data_20250909.csv, FHOVPRNC001 Parsed_Data_20250909.csv, FHOVPRNB001 Parsed_Data_20250909.csv, FHOVPRNA001 Parsed_Data_20250909.csv</td>\n",
              "      <td>file-1YQZUW1KHTwWzN7E8rbVer, file-YX11Ht6JTKnFdFeRfxj8Qg, file-XCMYLaqbJZaMgy2JVFC4WE, file-VUciHnTy49zQ1KjgVWV4oF, file-VuYRoRVxuEBFZKZjX95P4x, file-Wzh28UZqpzwDHegtgLbxjw</td>\n",
              "      <td>e10e7397-4a61-4c68-8d19-9a4e8e37b0b8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-09 14:37:28.230157-04:00</td>\n",
              "      <td>system</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>18731f11-b470-493c-9d97-2a74f1a64e21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-09 14:37:28.244915-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td>import pandas as pd\\r\\nimport glob\\r\\nimport os\\r\\n\\r\\n# File paths from uploaded files\\r\\nfiles = [\\r\\n    \"/mnt/data/FHOVPRNF001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNE001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRND001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNC001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNB001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNA001 Parsed_Data_20250909.csv\",\\r\\n]\\r\\n\\r\\n# Load all CSVs into a single DataFrame with PrintServer identification\\r\\ndf_list = []\\r\\nfor f in files:\\r\\n    try:\\r\\n        temp = pd.read_csv(f)\\r\\n        temp[\"PrintServer\"] = os.path.basename(f).split()[0]  # Extract server name\\r\\n        df_list.append(temp)\\r\\n    except Exception as e:\\r\\n        print(f\"Error reading {f}: {e}\")\\r\\n\\r\\ndf = pd.concat(df_list, ignore_index=True)\\r\\n\\r\\n# Inspect structure\\r\\ndf.head()</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>53c42575-de9f-45f1-b08e-62e02bf56b55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-09 14:37:42.307995-04:00</td>\n",
              "      <td>tool</td>\n",
              "      <td>None</td>\n",
              "      <td>Code execution state reset.</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>6bab5cdd-e406-49f1-8d74-62ef06fdf78c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-09 14:37:42.506574-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td>import pandas as pd\\r\\nimport os\\r\\n\\r\\n# File paths again after reset\\r\\nfiles = [\\r\\n    \"/mnt/data/FHOVPRNF001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNE001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRND001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNC001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNB001 Parsed_Data_20250909.csv\",\\r\\n    \"/mnt/data/FHOVPRNA001 Parsed_Data_20250909.csv\",\\r\\n]\\r\\n\\r\\n# Load all CSVs into a single DataFrame with PrintServer identification\\r\\ndf_list = []\\r\\nfor f in files:\\r\\n    try:\\r\\n        temp = pd.read_csv(f)\\r\\n        temp[\"PrintServer\"] = os.path.basename(f).split()[0]  # Extract server name\\r\\n        df_list.append(temp)\\r\\n    except Exception as e:\\r\\n        print(f\"Error reading {f}: {e}\")\\r\\n\\r\\ndf = pd.concat(df_list, ignore_index=True)\\r\\n\\r\\n# Show first rows and columns to understand structure\\r\\ndf.head(), df.columns</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>34fb6727-f2e0-499d-84d1-bce66561bb67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-09 14:37:48.416167-04:00</td>\n",
              "      <td>tool</td>\n",
              "      <td>None</td>\n",
              "      <td>(            TimeCreated    User        Machine  \\\\n 0  9/9/2025 11:41:43 AM  DPOC63    FMGLD1THD74   \\n 1  9/9/2025 11:41:32 AM  KGE87C    FMGD51KCPR3   \\n 2  9/9/2025 11:41:22 AM  NLWF4E    ALTDGRG1PK3   \\n 3  9/9/2025 11:41:11 AM  AKC365    FMGD9D9LG04   \\n 4  9/9/2025 11:41:04 AM  BMAAB0  FMGDAHBXZMMH3   \\n \\n                                         DocumentName Printer  PrintServer  \\\\n 0                                            Hybrent    OPA4  FHOVPRNF001   \\n 1                                        about_blank    NGF4  FHOVPRNF001   \\n 2                                        request.pdf    IWF2  FHOVPRNF001   \\n 3  Insurance Card - MRN_ 506269459 - Pt. Name_ BR...    NF82  FHOVPRNF001   \\n 4    EpicPDFSpooler_24BBCE7CA96E4BFB8E6A3303E2E42F17    OMJZ  FHOVPRNF001   \\n \\n      PrinterPort  SizeMB  PagesPrinted  \\n 0   10.100.39.52    0.86             1  \\n 1  10.28.244.217    0.38             2  \\n 2  10.16.246.255   31.09             2  \\n 3   10.48.247.51    0.21             1  \\n 4     10.89.8.29    0.28             1  ,\\n Index(['TimeCreated', 'User', 'Machine', 'DocumentName', 'Printer',\\n        'PrintServer', 'PrinterPort', 'SizeMB', 'PagesPrinted'],\\n       dtype='object'))</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>45642b36-1e73-474e-acdb-65a88bbe9350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-09 14:37:49.781429-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td># Convert TimeCreated to datetime for grouping by date\\r\\ndf[\"TimeCreated\"] = pd.to_datetime(df[\"TimeCreated\"], errors=\"coerce\")\\r\\n\\r\\n# Extract date only\\r\\ndf[\"Date\"] = df[\"TimeCreated\"].dt.date\\r\\n\\r\\n# Group by PrintServer and Date\\r\\nsummary = df.groupby([\"PrintServer\", \"Date\"]).agg(\\r\\n    NumberOfPrinters=(\"Printer\", \"nunique\"),\\r\\n    TotalSizeMB=(\"SizeMB\", \"sum\"),\\r\\n    TotalPages=(\"PagesPrinted\", \"sum\")\\r\\n).reset_index()\\r\\n\\r\\n# Save to Excel\\r\\noutput_path = \"/mnt/data/PrintServer_Summary.xlsx\"\\r\\nsummary.to_excel(output_path, index=False)\\r\\n\\r\\nimport ace_tools as tools; tools.display_dataframe_to_user(\"Print Server Summary\", summary)\\r\\n\\r\\noutput_path</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>889f475c-7a21-42c6-b099-6715b89c64b9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-09-09 14:37:56.237101-04:00</td>\n",
              "      <td>tool</td>\n",
              "      <td>None</td>\n",
              "      <td>'/mnt/data/PrintServer_Summary.xlsx'</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>9aec3d6d-49ac-45d0-a547-275538826cae</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2025-09-09 14:37:57.812203-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td>I‚Äôve parsed the data and created a summary Excel file that shows:  \\n\\n- **PrintServer**  \\n- **Date**  \\n- **Number of Printers**  \\n- **Total Size (MB)**  \\n- **Total Pages Printed**  \\n\\nüìÇ [Download PrintServer Summary Excel](sandbox:/mnt/data/PrintServer_Summary.xlsx)  \\n\\nWould you like me to also create a **per-printer breakdown** (not just server-level) so you can see printer-level usage trends?</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>6a3ba228-f2d1-4052-be61-adad34002242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-09-09 14:40:48.676000-04:00</td>\n",
              "      <td>user</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>7e5cc5ed-1f29-45a6-bc85-1f9d25b46c5b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2025-09-09 14:40:49.797065-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td># Create per-printer breakdown grouped by PrintServer, Date, and Printer\\r\\nprinter_summary = df.groupby([\"PrintServer\", \"Date\", \"Printer\"]).agg(\\r\\n    TotalSizeMB=(\"SizeMB\", \"sum\"),\\r\\n    TotalPages=(\"PagesPrinted\", \"sum\")\\r\\n).reset_index()\\r\\n\\r\\n# Save to Excel with two sheets: Server summary + Printer summary\\r\\noutput_path_detailed = \"/mnt/data/PrintServer_Detailed_Summary.xlsx\"\\r\\n\\r\\nwith pd.ExcelWriter(output_path_detailed, engine=\"xlsxwriter\") as writer:\\r\\n    summary.to_excel(writer, sheet_name=\"Server_Summary\", index=False)\\r\\n    printer_summary.to_excel(writer, sheet_name=\"Printer_Summary\", index=False)\\r\\n\\r\\nimport ace_tools as tools; tools.display_dataframe_to_user(\"Print Server Detailed Summary\", printer_summary)\\r\\n\\r\\noutput_path_detailed</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>ac318088-76c3-405f-b69a-5bc49be19e3a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-09-09 14:40:56.966395-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td># Group by PrintServer, Date, and individual Printer\\r\\nper_printer_summary = df.groupby([\"PrintServer\", \"Date\", \"Printer\"]).agg(\\r\\n    TotalSizeMB=(\"SizeMB\", \"sum\"),\\r\\n    TotalPages=(\"PagesPrinted\", \"sum\")\\r\\n).reset_index()\\r\\n\\r\\n# Save to Excel with two sheets: Server Summary + Printer Breakdown\\r\\noutput_path_detailed = \"/mnt/data/PrintServer_Detailed_Summary.xlsx\"\\r\\nwith pd.ExcelWriter(output_path_detailed, engine=\"xlsxwriter\") as writer:\\r\\n    summary.to_excel(writer, sheet_name=\"Server_Summary\", index=False)\\r\\n    per_printer_summary.to_excel(writer, sheet_name=\"Per_Printer_Breakdown\", index=False)\\r\\n\\r\\nimport ace_tools as tools; tools.display_dataframe_to_user(\"Print Server Detailed Summary\", per_printer_summary)\\r\\n\\r\\noutput_path_detailed</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>6623df83-e59c-49a1-ad1d-17a8b59a7b71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2025-09-09 14:40:57.405377-04:00</td>\n",
              "      <td>tool</td>\n",
              "      <td>None</td>\n",
              "      <td>'/mnt/data/PrintServer_Detailed_Summary.xlsx'</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>05526889-918e-4c68-a3f0-616fd1189830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2025-09-09 14:40:58.391165-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td>Here‚Äôs the updated Excel file with **two sheets**:  \\n\\n- **Server_Summary** ‚Üí Total printers, pages, and size per server per day  \\n- **Printer_Summary** ‚Üí Detailed breakdown per printer, per server, per day  \\n\\nüìÇ [Download PrintServer Detailed Summary Excel](sandbox:/mnt/data/PrintServer_Detailed_Summary.xlsx)  \\n\\nDo you want me to also add **charts** (e.g., pages per server over time) inside the Excel for easier visualization?</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>02c5c52f-951c-402e-bf0a-b118582628a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2025-09-09 14:41:04.573895-04:00</td>\n",
              "      <td>tool</td>\n",
              "      <td>None</td>\n",
              "      <td>'/mnt/data/PrintServer_Detailed_Summary.xlsx'</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>b23648b7-7e1e-42a6-96f2-51043a939faf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2025-09-09 14:41:05.219232-04:00</td>\n",
              "      <td>assistant</td>\n",
              "      <td>None</td>\n",
              "      <td>Here‚Äôs the enhanced Excel report with **two sheets**:  \\n\\n1. **Server_Summary** ‚Üí Totals per PrintServer per date  \\n2. **Per_Printer_Breakdown** ‚Üí Usage per Printer (SizeMB &amp; Pages)  \\n\\nüìÇ [Download Detailed PrintServer Summary Excel](sandbox:/mnt/data/PrintServer_Detailed_Summary.xlsx)  \\n\\nDo you want me to also add **charts/visuals** (e.g., pages printed per server over time)?</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>f62f79e1-b819-424f-b047-8121a54f2fac</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df36af9f-4b7a-4824-b355-9ef28e0904d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df36af9f-4b7a-4824-b355-9ef28e0904d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df36af9f-4b7a-4824-b355-9ef28e0904d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-30942660-5d70-4314-a1f9-947c1afb101e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30942660-5d70-4314-a1f9-947c1afb101e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-30942660-5d70-4314-a1f9-947c1afb101e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: show a window of messages around a given message_id, including file info\n",
        "def convo_thread_window(df_msgs: pd.DataFrame,\n",
        "                        anchor_message_id: str,\n",
        "                        before: int = 3,\n",
        "                        after: int = 3) -> pd.DataFrame:\n",
        "    if df_msgs is None or df_msgs.empty:\n",
        "        print(\"No df_msgs loaded.\")\n",
        "        return pd.DataFrame()\n",
        "    df_sorted = df_msgs.sort_values(\"message_created_at\").reset_index(drop=True)\n",
        "    idx = df_sorted.index[df_sorted[\"message_id\"] == anchor_message_id]\n",
        "    if len(idx) == 0:\n",
        "        print(\"Message not found:\", anchor_message_id)\n",
        "        return pd.DataFrame()\n",
        "    i = int(idx[0])\n",
        "    start_i, end_i = max(0, i - before), min(len(df_sorted), i + after + 1)\n",
        "    window = df_sorted.iloc[start_i:end_i].copy()\n",
        "    display(window[[\n",
        "        \"message_created_at_et\",\"author_role\",\"author_email\",\"content_value\",\n",
        "        \"file_count\",\"file_names\",\"file_ids\",\"message_id\"\n",
        "    ]])\n",
        "    return window\n",
        "\n",
        "# Example:\n",
        "# anchor_id = df_msgs.iloc[5][\"message_id\"]\n",
        "# convo_thread_window(df_msgs, anchor_id, before=5, after=5)\n"
      ],
      "metadata": {
        "id": "cpFQOCtaUVYo"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO4qVMzm60PG8MlbEaMnBQM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}